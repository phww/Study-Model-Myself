2021-06-10::12-54-47
*************** epoch:1 ***************
loss: 9.37852	cur:[0]\[10618]
loss: 3.02778	cur:[1000]\[10618]
loss: 2.76803	cur:[2000]\[10618]
loss: 2.59208	cur:[3000]\[10618]
loss: 2.48997	cur:[4000]\[10618]
loss: 2.40634	cur:[5000]\[10618]
loss: 2.35873	cur:[6000]\[10618]
loss: 2.31969	cur:[7000]\[10618]
loss: 2.28042	cur:[8000]\[10618]
loss: 2.23843	cur:[9000]\[10618]
loss: 2.21876	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 2.14907	cur:[250]\[1320]
loss: 2.11274	cur:[500]\[1320]
loss: 2.12728	cur:[750]\[1320]
loss: 2.13719	cur:[1000]\[1320]
loss: 2.13374	cur:[1250]\[1320]
save model at ./check_point5/best.pth
epoch:1	bleu:0.00000
*************** epoch:2 ***************
loss: 2.16622	cur:[1000]\[10618]
loss: 2.14422	cur:[2000]\[10618]
loss: 2.13881	cur:[3000]\[10618]
loss: 2.12777	cur:[4000]\[10618]
loss: 2.09583	cur:[5000]\[10618]
loss: 2.12627	cur:[6000]\[10618]
loss: 2.08540	cur:[7000]\[10618]
loss: 2.08531	cur:[8000]\[10618]
loss: 2.06605	cur:[9000]\[10618]
loss: 2.07415	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 2.04314	cur:[250]\[1320]
loss: 2.00632	cur:[500]\[1320]
loss: 1.97462	cur:[750]\[1320]
loss: 2.01863	cur:[1000]\[1320]
loss: 2.03051	cur:[1250]\[1320]
epoch:2	bleu:0.00000
*************** epoch:3 ***************
loss: 2.06896	cur:[1000]\[10618]
loss: 2.04882	cur:[2000]\[10618]
loss: 2.03043	cur:[3000]\[10618]
loss: 2.02961	cur:[4000]\[10618]
loss: 2.04369	cur:[5000]\[10618]
loss: 2.00347	cur:[6000]\[10618]
loss: 2.00156	cur:[7000]\[10618]
loss: 2.00817	cur:[8000]\[10618]
loss: 2.00041	cur:[9000]\[10618]
loss: 1.97335	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.96715	cur:[250]\[1320]
loss: 1.95553	cur:[500]\[1320]
loss: 1.95793	cur:[750]\[1320]
loss: 1.96067	cur:[1000]\[1320]
loss: 1.96643	cur:[1250]\[1320]
save model at ./check_point5/best.pth
epoch:3	bleu:0.02850
*************** epoch:4 ***************
loss: 1.98730	cur:[1000]\[10618]
loss: 1.98080	cur:[2000]\[10618]
loss: 1.96540	cur:[3000]\[10618]
loss: 1.96559	cur:[4000]\[10618]
loss: 1.96432	cur:[5000]\[10618]
loss: 1.95039	cur:[6000]\[10618]
loss: 1.93121	cur:[7000]\[10618]
loss: 1.94166	cur:[8000]\[10618]
loss: 1.92808	cur:[9000]\[10618]
loss: 1.92532	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.92082	cur:[250]\[1320]
loss: 1.89190	cur:[500]\[1320]
loss: 1.90781	cur:[750]\[1320]
loss: 1.91455	cur:[1000]\[1320]
loss: 1.89601	cur:[1250]\[1320]
epoch:4	bleu:0.00000
*************** epoch:5 ***************
loss: 1.91043	cur:[1000]\[10618]
loss: 1.90534	cur:[2000]\[10618]
loss: 1.91434	cur:[3000]\[10618]
loss: 1.88669	cur:[4000]\[10618]
loss: 1.86783	cur:[5000]\[10618]
loss: 1.87733	cur:[6000]\[10618]
loss: 1.88770	cur:[7000]\[10618]
loss: 1.85895	cur:[8000]\[10618]
loss: 1.86368	cur:[9000]\[10618]
loss: 1.87801	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.81129	cur:[250]\[1320]
loss: 1.90221	cur:[500]\[1320]
loss: 1.87643	cur:[750]\[1320]
loss: 1.85280	cur:[1000]\[1320]
loss: 1.85148	cur:[1250]\[1320]
epoch:5	bleu:0.00000
*************** epoch:6 ***************
loss: 1.86370	cur:[1000]\[10618]
loss: 1.83431	cur:[2000]\[10618]
loss: 1.82518	cur:[3000]\[10618]
loss: 1.81951	cur:[4000]\[10618]
loss: 1.82097	cur:[5000]\[10618]
loss: 1.82358	cur:[6000]\[10618]
loss: 1.81532	cur:[7000]\[10618]
loss: 1.80239	cur:[8000]\[10618]
loss: 1.81586	cur:[9000]\[10618]
loss: 1.81635	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.81323	cur:[250]\[1320]
loss: 1.80917	cur:[500]\[1320]
loss: 1.80486	cur:[750]\[1320]
loss: 1.84843	cur:[1000]\[1320]
loss: 1.83501	cur:[1250]\[1320]
epoch:6	bleu:0.02336
*************** epoch:7 ***************
loss: 1.79057	cur:[1000]\[10618]
loss: 1.79231	cur:[2000]\[10618]
loss: 1.78407	cur:[3000]\[10618]
loss: 1.77725	cur:[4000]\[10618]
loss: 1.76745	cur:[5000]\[10618]
loss: 1.76412	cur:[6000]\[10618]
loss: 1.76198	cur:[7000]\[10618]
loss: 1.76155	cur:[8000]\[10618]
loss: 1.74524	cur:[9000]\[10618]
loss: 1.75758	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.80872	cur:[250]\[1320]
loss: 1.80058	cur:[500]\[1320]
loss: 1.78048	cur:[750]\[1320]
loss: 1.81679	cur:[1000]\[1320]
loss: 1.79122	cur:[1250]\[1320]
epoch:7	bleu:0.00000
*************** epoch:8 ***************
loss: 1.73931	cur:[1000]\[10618]
loss: 1.72761	cur:[2000]\[10618]
loss: 1.73097	cur:[3000]\[10618]
loss: 1.73977	cur:[4000]\[10618]
loss: 1.71798	cur:[5000]\[10618]
loss: 1.70875	cur:[6000]\[10618]
loss: 1.72438	cur:[7000]\[10618]
loss: 1.74830	cur:[8000]\[10618]
loss: 1.70429	cur:[9000]\[10618]
loss: 1.70196	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.75301	cur:[250]\[1320]
loss: 1.72336	cur:[500]\[1320]
loss: 1.74454	cur:[750]\[1320]
loss: 1.77498	cur:[1000]\[1320]
loss: 1.75692	cur:[1250]\[1320]
save model at ./check_point5/best.pth
epoch:8	bleu:0.04152
*************** epoch:9 ***************
loss: 1.69940	cur:[1000]\[10618]
loss: 1.68438	cur:[2000]\[10618]
loss: 1.70873	cur:[3000]\[10618]
loss: 1.67337	cur:[4000]\[10618]
loss: 1.69913	cur:[5000]\[10618]
loss: 1.67833	cur:[6000]\[10618]
loss: 1.69312	cur:[7000]\[10618]
loss: 1.68613	cur:[8000]\[10618]
loss: 1.70416	cur:[9000]\[10618]
loss: 1.66721	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.70898	cur:[250]\[1320]
loss: 1.74367	cur:[500]\[1320]
loss: 1.73540	cur:[750]\[1320]
loss: 1.70359	cur:[1000]\[1320]
loss: 1.73025	cur:[1250]\[1320]
epoch:9	bleu:0.00000
*************** epoch:10 ***************
loss: 1.67387	cur:[1000]\[10618]
loss: 1.66184	cur:[2000]\[10618]
loss: 1.63686	cur:[3000]\[10618]
loss: 1.67757	cur:[4000]\[10618]
loss: 1.65613	cur:[5000]\[10618]
loss: 1.65140	cur:[6000]\[10618]
loss: 1.67199	cur:[7000]\[10618]
loss: 1.65183	cur:[8000]\[10618]
loss: 1.65674	cur:[9000]\[10618]
loss: 1.62673	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.69908	cur:[250]\[1320]
loss: 1.64781	cur:[500]\[1320]
loss: 1.67020	cur:[750]\[1320]
loss: 1.69921	cur:[1000]\[1320]
loss: 1.77640	cur:[1250]\[1320]
save model at ./check_point5/best.pth
save model at ./check_point5/epoch10.pth
epoch:10	bleu:0.05000
*************** epoch:11 ***************
loss: 1.64527	cur:[1000]\[10618]
loss: 1.62805	cur:[2000]\[10618]
loss: 1.62700	cur:[3000]\[10618]
loss: 1.62800	cur:[4000]\[10618]
loss: 1.62491	cur:[5000]\[10618]
loss: 1.61612	cur:[6000]\[10618]
loss: 1.61115	cur:[7000]\[10618]
loss: 1.65228	cur:[8000]\[10618]
loss: 1.59975	cur:[9000]\[10618]
loss: 1.63456	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.63230	cur:[250]\[1320]
loss: 1.65696	cur:[500]\[1320]
loss: 1.68989	cur:[750]\[1320]
loss: 1.69341	cur:[1000]\[1320]
loss: 1.67341	cur:[1250]\[1320]
save model at ./check_point5/best.pth
epoch:11	bleu:0.05000
*************** epoch:12 ***************
loss: 1.58243	cur:[1000]\[10618]
loss: 1.62018	cur:[2000]\[10618]
loss: 1.60250	cur:[3000]\[10618]
loss: 1.58346	cur:[4000]\[10618]
loss: 1.62022	cur:[5000]\[10618]
loss: 1.57877	cur:[6000]\[10618]
loss: 1.58128	cur:[7000]\[10618]
loss: 1.60235	cur:[8000]\[10618]
loss: 1.58798	cur:[9000]\[10618]
loss: 1.58867	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.66486	cur:[250]\[1320]
loss: 1.64308	cur:[500]\[1320]
loss: 1.67267	cur:[750]\[1320]
loss: 1.64784	cur:[1000]\[1320]
loss: 1.66671	cur:[1250]\[1320]
save model at ./check_point5/best.pth
epoch:12	bleu:0.05109
*************** epoch:13 ***************
loss: 1.56152	cur:[1000]\[10618]
loss: 1.58300	cur:[2000]\[10618]
loss: 1.59009	cur:[3000]\[10618]
loss: 1.59285	cur:[4000]\[10618]
loss: 1.56465	cur:[5000]\[10618]
loss: 1.55560	cur:[6000]\[10618]
loss: 1.56157	cur:[7000]\[10618]
loss: 1.55253	cur:[8000]\[10618]
loss: 1.55969	cur:[9000]\[10618]
loss: 1.56233	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.65901	cur:[250]\[1320]
loss: 1.63198	cur:[500]\[1320]
loss: 1.67816	cur:[750]\[1320]
loss: 1.61746	cur:[1000]\[1320]
loss: 1.65083	cur:[1250]\[1320]
epoch:13	bleu:0.00000
*************** epoch:14 ***************
loss: 1.54362	cur:[1000]\[10618]
loss: 1.57254	cur:[2000]\[10618]
loss: 1.55876	cur:[3000]\[10618]
loss: 1.53592	cur:[4000]\[10618]
loss: 1.56475	cur:[5000]\[10618]
loss: 1.54635	cur:[6000]\[10618]
loss: 1.53905	cur:[7000]\[10618]
loss: 1.52124	cur:[8000]\[10618]
loss: 1.52585	cur:[9000]\[10618]
loss: 1.52586	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.65119	cur:[250]\[1320]
loss: 1.61234	cur:[500]\[1320]
loss: 1.59901	cur:[750]\[1320]
loss: 1.64370	cur:[1000]\[1320]
loss: 1.65337	cur:[1250]\[1320]
epoch:14	bleu:0.03761
*************** epoch:15 ***************
loss: 1.52813	cur:[1000]\[10618]
loss: 1.54615	cur:[2000]\[10618]
loss: 1.53731	cur:[3000]\[10618]
loss: 1.52250	cur:[4000]\[10618]
loss: 1.50767	cur:[5000]\[10618]
loss: 1.50629	cur:[6000]\[10618]
loss: 1.51124	cur:[7000]\[10618]
loss: 1.47763	cur:[8000]\[10618]
loss: 1.51205	cur:[9000]\[10618]
loss: 1.53132	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.63336	cur:[250]\[1320]
loss: 1.62730	cur:[500]\[1320]
loss: 1.65556	cur:[750]\[1320]
loss: 1.62796	cur:[1000]\[1320]
loss: 1.61367	cur:[1250]\[1320]
save model at ./check_point5/best.pth
epoch:15	bleu:0.07320
*************** epoch:16 ***************
loss: 1.49764	cur:[1000]\[10618]
loss: 1.50972	cur:[2000]\[10618]
loss: 1.52652	cur:[3000]\[10618]
loss: 1.50163	cur:[4000]\[10618]
loss: 1.49020	cur:[5000]\[10618]
loss: 1.51163	cur:[6000]\[10618]
loss: 1.49078	cur:[7000]\[10618]
loss: 1.49874	cur:[8000]\[10618]
loss: 1.50169	cur:[9000]\[10618]
loss: 1.51473	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.62033	cur:[250]\[1320]
loss: 1.61947	cur:[500]\[1320]
loss: 1.59740	cur:[750]\[1320]
loss: 1.59217	cur:[1000]\[1320]
loss: 1.63371	cur:[1250]\[1320]
epoch:16	bleu:0.05818
*************** epoch:17 ***************
loss: 1.50549	cur:[1000]\[10618]
loss: 1.48597	cur:[2000]\[10618]
loss: 1.48109	cur:[3000]\[10618]
loss: 1.48797	cur:[4000]\[10618]
loss: 1.47285	cur:[5000]\[10618]
loss: 1.49023	cur:[6000]\[10618]
loss: 1.47348	cur:[7000]\[10618]
loss: 1.46145	cur:[8000]\[10618]
loss: 1.49236	cur:[9000]\[10618]
loss: 1.46853	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.58237	cur:[250]\[1320]
loss: 1.60483	cur:[500]\[1320]
loss: 1.59993	cur:[750]\[1320]
loss: 1.60002	cur:[1000]\[1320]
loss: 1.56362	cur:[1250]\[1320]
save model at ./check_point5/best.pth
epoch:17	bleu:0.08303
*************** epoch:18 ***************
loss: 1.49460	cur:[1000]\[10618]
loss: 1.47024	cur:[2000]\[10618]
loss: 1.47570	cur:[3000]\[10618]
loss: 1.45607	cur:[4000]\[10618]
loss: 1.46669	cur:[5000]\[10618]
loss: 1.46759	cur:[6000]\[10618]
loss: 1.45751	cur:[7000]\[10618]
loss: 1.46573	cur:[8000]\[10618]
loss: 1.46217	cur:[9000]\[10618]
loss: 1.44685	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.57219	cur:[250]\[1320]
loss: 1.56568	cur:[500]\[1320]
loss: 1.55107	cur:[750]\[1320]
loss: 1.60760	cur:[1000]\[1320]
loss: 1.56267	cur:[1250]\[1320]
epoch:18	bleu:0.02056
*************** epoch:19 ***************
loss: 1.46203	cur:[1000]\[10618]
loss: 1.45892	cur:[2000]\[10618]
loss: 1.44440	cur:[3000]\[10618]
loss: 1.45115	cur:[4000]\[10618]
loss: 1.44405	cur:[5000]\[10618]
loss: 1.41966	cur:[6000]\[10618]
loss: 1.45441	cur:[7000]\[10618]
loss: 1.40615	cur:[8000]\[10618]
loss: 1.43375	cur:[9000]\[10618]
loss: 1.42367	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.60064	cur:[250]\[1320]
loss: 1.59713	cur:[500]\[1320]
loss: 1.56253	cur:[750]\[1320]
loss: 1.50496	cur:[1000]\[1320]
loss: 1.54769	cur:[1250]\[1320]
epoch:19	bleu:0.02412
*************** epoch:20 ***************
loss: 1.46006	cur:[1000]\[10618]
loss: 1.45495	cur:[2000]\[10618]
loss: 1.40991	cur:[3000]\[10618]
loss: 1.45237	cur:[4000]\[10618]
loss: 1.42229	cur:[5000]\[10618]
loss: 1.43413	cur:[6000]\[10618]
loss: 1.43167	cur:[7000]\[10618]
loss: 1.41465	cur:[8000]\[10618]
loss: 1.41451	cur:[9000]\[10618]
loss: 1.42729	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.55426	cur:[250]\[1320]
loss: 1.53947	cur:[500]\[1320]
loss: 1.57807	cur:[750]\[1320]
loss: 1.53192	cur:[1000]\[1320]
loss: 1.57208	cur:[1250]\[1320]
save model at ./check_point5/epoch20.pth
epoch:20	bleu:0.00000
*************** epoch:21 ***************
loss: 1.42778	cur:[1000]\[10618]
loss: 1.40531	cur:[2000]\[10618]
loss: 1.40506	cur:[3000]\[10618]
loss: 1.42301	cur:[4000]\[10618]
loss: 1.42161	cur:[5000]\[10618]
loss: 1.42647	cur:[6000]\[10618]
loss: 1.43389	cur:[7000]\[10618]
loss: 1.39434	cur:[8000]\[10618]
loss: 1.40748	cur:[9000]\[10618]
loss: 1.40699	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.57419	cur:[250]\[1320]
loss: 1.56951	cur:[500]\[1320]
loss: 1.54354	cur:[750]\[1320]
loss: 1.52750	cur:[1000]\[1320]
loss: 1.52451	cur:[1250]\[1320]
epoch:21	bleu:0.00000
*************** epoch:22 ***************
loss: 1.39550	cur:[1000]\[10618]
loss: 1.41391	cur:[2000]\[10618]
loss: 1.41129	cur:[3000]\[10618]
loss: 1.38351	cur:[4000]\[10618]
loss: 1.39446	cur:[5000]\[10618]
loss: 1.40096	cur:[6000]\[10618]
loss: 1.40211	cur:[7000]\[10618]
loss: 1.39662	cur:[8000]\[10618]
loss: 1.38262	cur:[9000]\[10618]
loss: 1.38563	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.55288	cur:[250]\[1320]
loss: 1.58846	cur:[500]\[1320]
loss: 1.54303	cur:[750]\[1320]
loss: 1.57380	cur:[1000]\[1320]
loss: 1.50131	cur:[1250]\[1320]
epoch:22	bleu:0.01175
*************** epoch:23 ***************
loss: 1.38003	cur:[1000]\[10618]
loss: 1.36512	cur:[2000]\[10618]
loss: 1.39078	cur:[3000]\[10618]
loss: 1.38413	cur:[4000]\[10618]
loss: 1.37864	cur:[5000]\[10618]
loss: 1.38318	cur:[6000]\[10618]
loss: 1.38093	cur:[7000]\[10618]
loss: 1.39119	cur:[8000]\[10618]
loss: 1.36757	cur:[9000]\[10618]
loss: 1.38756	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.51849	cur:[250]\[1320]
loss: 1.56105	cur:[500]\[1320]
loss: 1.55332	cur:[750]\[1320]
loss: 1.57650	cur:[1000]\[1320]
loss: 1.54659	cur:[1250]\[1320]
epoch:23	bleu:0.00000
*************** epoch:24 ***************
loss: 1.36025	cur:[1000]\[10618]
loss: 1.38783	cur:[2000]\[10618]
loss: 1.36752	cur:[3000]\[10618]
loss: 1.34820	cur:[4000]\[10618]
loss: 1.35525	cur:[5000]\[10618]
loss: 1.36165	cur:[6000]\[10618]
loss: 1.37501	cur:[7000]\[10618]
loss: 1.38854	cur:[8000]\[10618]
loss: 1.36298	cur:[9000]\[10618]
loss: 1.35199	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.52055	cur:[250]\[1320]
loss: 1.47723	cur:[500]\[1320]
loss: 1.55762	cur:[750]\[1320]
loss: 1.57096	cur:[1000]\[1320]
loss: 1.56509	cur:[1250]\[1320]
epoch:24	bleu:0.03651
*************** epoch:25 ***************
loss: 1.34438	cur:[1000]\[10618]
loss: 1.36743	cur:[2000]\[10618]
loss: 1.35893	cur:[3000]\[10618]
loss: 1.33939	cur:[4000]\[10618]
loss: 1.37386	cur:[5000]\[10618]
loss: 1.32498	cur:[6000]\[10618]
loss: 1.35839	cur:[7000]\[10618]
loss: 1.32506	cur:[8000]\[10618]
loss: 1.33619	cur:[9000]\[10618]
loss: 1.33967	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.57428	cur:[250]\[1320]
loss: 1.49089	cur:[500]\[1320]
loss: 1.57800	cur:[750]\[1320]
loss: 1.55833	cur:[1000]\[1320]
loss: 1.52260	cur:[1250]\[1320]
epoch:25	bleu:0.00000
*************** epoch:26 ***************
loss: 1.34923	cur:[1000]\[10618]
loss: 1.34572	cur:[2000]\[10618]
loss: 1.33701	cur:[3000]\[10618]
loss: 1.34244	cur:[4000]\[10618]
loss: 1.33863	cur:[5000]\[10618]
loss: 1.32369	cur:[6000]\[10618]
loss: 1.32270	cur:[7000]\[10618]
loss: 1.32313	cur:[8000]\[10618]
loss: 1.31693	cur:[9000]\[10618]
loss: 1.31739	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.50271	cur:[250]\[1320]
loss: 1.59000	cur:[500]\[1320]
loss: 1.52199	cur:[750]\[1320]
loss: 1.52197	cur:[1000]\[1320]
loss: 1.53472	cur:[1250]\[1320]
epoch:26	bleu:0.00000
*************** epoch:27 ***************
loss: 1.33773	cur:[1000]\[10618]
loss: 1.32519	cur:[2000]\[10618]
loss: 1.29489	cur:[3000]\[10618]
loss: 1.34103	cur:[4000]\[10618]
loss: 1.31606	cur:[5000]\[10618]
loss: 1.30601	cur:[6000]\[10618]
loss: 1.31717	cur:[7000]\[10618]
loss: 1.33692	cur:[8000]\[10618]
loss: 1.30978	cur:[9000]\[10618]
loss: 1.30946	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.52501	cur:[250]\[1320]
loss: 1.51108	cur:[500]\[1320]
loss: 1.50180	cur:[750]\[1320]
loss: 1.56465	cur:[1000]\[1320]
loss: 1.51291	cur:[1250]\[1320]
epoch:27	bleu:0.07778
*************** epoch:28 ***************
loss: 1.28663	cur:[1000]\[10618]
loss: 1.32347	cur:[2000]\[10618]
loss: 1.33180	cur:[3000]\[10618]
loss: 1.33080	cur:[4000]\[10618]
loss: 1.31516	cur:[5000]\[10618]
loss: 1.32846	cur:[6000]\[10618]
loss: 1.31723	cur:[7000]\[10618]
loss: 1.30818	cur:[8000]\[10618]
loss: 1.31079	cur:[9000]\[10618]
loss: 1.28543	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.47299	cur:[250]\[1320]
loss: 1.55105	cur:[500]\[1320]
loss: 1.52000	cur:[750]\[1320]
loss: 1.56565	cur:[1000]\[1320]
loss: 1.56616	cur:[1250]\[1320]
epoch:28	bleu:0.04618
*************** epoch:29 ***************
loss: 1.30450	cur:[1000]\[10618]
loss: 1.30655	cur:[2000]\[10618]
loss: 1.27745	cur:[3000]\[10618]
loss: 1.28793	cur:[4000]\[10618]
loss: 1.28430	cur:[5000]\[10618]
loss: 1.31021	cur:[6000]\[10618]
loss: 1.29138	cur:[7000]\[10618]
loss: 1.29681	cur:[8000]\[10618]
loss: 1.29069	cur:[9000]\[10618]
loss: 1.28968	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.50071	cur:[250]\[1320]
loss: 1.54629	cur:[500]\[1320]
loss: 1.45573	cur:[750]\[1320]
loss: 1.49630	cur:[1000]\[1320]
loss: 1.47921	cur:[1250]\[1320]
save model at ./check_point5/best.pth
epoch:29	bleu:0.10000
*************** epoch:30 ***************
loss: 1.28915	cur:[1000]\[10618]
loss: 1.29593	cur:[2000]\[10618]
loss: 1.29808	cur:[3000]\[10618]
loss: 1.29266	cur:[4000]\[10618]
loss: 1.28218	cur:[5000]\[10618]
loss: 1.27768	cur:[6000]\[10618]
loss: 1.29273	cur:[7000]\[10618]
loss: 1.28230	cur:[8000]\[10618]
loss: 1.25898	cur:[9000]\[10618]
loss: 1.28024	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.51372	cur:[250]\[1320]
loss: 1.54849	cur:[500]\[1320]
loss: 1.52472	cur:[750]\[1320]
loss: 1.53346	cur:[1000]\[1320]
loss: 1.51707	cur:[1250]\[1320]
save model at ./check_point5/epoch30.pth
epoch:30	bleu:0.07895
*************** epoch:31 ***************
loss: 1.26201	cur:[1000]\[10618]
loss: 1.29806	cur:[2000]\[10618]
loss: 1.27582	cur:[3000]\[10618]
loss: 1.26401	cur:[4000]\[10618]
loss: 1.26265	cur:[5000]\[10618]
loss: 1.27679	cur:[6000]\[10618]
loss: 1.29328	cur:[7000]\[10618]
loss: 1.25481	cur:[8000]\[10618]
loss: 1.29043	cur:[9000]\[10618]
loss: 1.25128	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.50622	cur:[250]\[1320]
loss: 1.47720	cur:[500]\[1320]
loss: 1.50209	cur:[750]\[1320]
loss: 1.48419	cur:[1000]\[1320]
loss: 1.48838	cur:[1250]\[1320]
epoch:31	bleu:0.02056
*************** epoch:32 ***************
loss: 1.26135	cur:[1000]\[10618]
loss: 1.26132	cur:[2000]\[10618]
loss: 1.25837	cur:[3000]\[10618]
loss: 1.26709	cur:[4000]\[10618]
loss: 1.27446	cur:[5000]\[10618]
loss: 1.24931	cur:[6000]\[10618]
loss: 1.27317	cur:[7000]\[10618]
loss: 1.26232	cur:[8000]\[10618]
loss: 1.26840	cur:[9000]\[10618]
loss: 1.25346	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.49762	cur:[250]\[1320]
loss: 1.48750	cur:[500]\[1320]
loss: 1.51510	cur:[750]\[1320]
loss: 1.53851	cur:[1000]\[1320]
loss: 1.48110	cur:[1250]\[1320]
epoch:32	bleu:0.02399
*************** epoch:33 ***************
loss: 1.26193	cur:[1000]\[10618]
loss: 1.26210	cur:[2000]\[10618]
loss: 1.23965	cur:[3000]\[10618]
loss: 1.23995	cur:[4000]\[10618]
loss: 1.24589	cur:[5000]\[10618]
loss: 1.25482	cur:[6000]\[10618]
loss: 1.22896	cur:[7000]\[10618]
loss: 1.23352	cur:[8000]\[10618]
loss: 1.25851	cur:[9000]\[10618]
loss: 1.24523	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.49489	cur:[250]\[1320]
loss: 1.53847	cur:[500]\[1320]
loss: 1.46703	cur:[750]\[1320]
loss: 1.44437	cur:[1000]\[1320]
loss: 1.48594	cur:[1250]\[1320]
epoch:33	bleu:0.09141
*************** epoch:34 ***************
loss: 1.23458	cur:[1000]\[10618]
loss: 1.25293	cur:[2000]\[10618]
loss: 1.24213	cur:[3000]\[10618]
loss: 1.22843	cur:[4000]\[10618]
loss: 1.22466	cur:[5000]\[10618]
loss: 1.25487	cur:[6000]\[10618]
loss: 1.24625	cur:[7000]\[10618]
loss: 1.23878	cur:[8000]\[10618]
loss: 1.25255	cur:[9000]\[10618]
loss: 1.21794	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.52520	cur:[250]\[1320]
loss: 1.49825	cur:[500]\[1320]
loss: 1.46337	cur:[750]\[1320]
loss: 1.55140	cur:[1000]\[1320]
loss: 1.52007	cur:[1250]\[1320]
epoch:34	bleu:0.00000
*************** epoch:35 ***************
loss: 1.23042	cur:[1000]\[10618]
loss: 1.25228	cur:[2000]\[10618]
loss: 1.23040	cur:[3000]\[10618]
loss: 1.21201	cur:[4000]\[10618]
loss: 1.23505	cur:[5000]\[10618]
loss: 1.20444	cur:[6000]\[10618]
loss: 1.21236	cur:[7000]\[10618]
loss: 1.22460	cur:[8000]\[10618]
loss: 1.21648	cur:[9000]\[10618]
loss: 1.21954	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.48969	cur:[250]\[1320]
loss: 1.50033	cur:[500]\[1320]
loss: 1.52353	cur:[750]\[1320]
loss: 1.53889	cur:[1000]\[1320]
loss: 1.48837	cur:[1250]\[1320]
epoch:35	bleu:0.02973
*************** epoch:36 ***************
loss: 1.21690	cur:[1000]\[10618]
loss: 1.23595	cur:[2000]\[10618]
loss: 1.22011	cur:[3000]\[10618]
loss: 1.22722	cur:[4000]\[10618]
loss: 1.22422	cur:[5000]\[10618]
loss: 1.19659	cur:[6000]\[10618]
loss: 1.22789	cur:[7000]\[10618]
loss: 1.21005	cur:[8000]\[10618]
loss: 1.20200	cur:[9000]\[10618]
loss: 1.20458	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.44201	cur:[250]\[1320]
loss: 1.52002	cur:[500]\[1320]
loss: 1.53169	cur:[750]\[1320]
loss: 1.49364	cur:[1000]\[1320]
loss: 1.47216	cur:[1250]\[1320]
epoch:36	bleu:0.01585
*************** epoch:37 ***************
loss: 1.20086	cur:[1000]\[10618]
loss: 1.23298	cur:[2000]\[10618]
loss: 1.21328	cur:[3000]\[10618]
loss: 1.22173	cur:[4000]\[10618]
loss: 1.19263	cur:[5000]\[10618]
loss: 1.19701	cur:[6000]\[10618]
loss: 1.22631	cur:[7000]\[10618]
loss: 1.21564	cur:[8000]\[10618]
loss: 1.20466	cur:[9000]\[10618]
loss: 1.18394	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.50226	cur:[250]\[1320]
loss: 1.49500	cur:[500]\[1320]
loss: 1.48383	cur:[750]\[1320]
loss: 1.43207	cur:[1000]\[1320]
loss: 1.51989	cur:[1250]\[1320]
epoch:37	bleu:0.00000
*************** epoch:38 ***************
loss: 1.21484	cur:[1000]\[10618]
loss: 1.20772	cur:[2000]\[10618]
loss: 1.21723	cur:[3000]\[10618]
loss: 1.19429	cur:[4000]\[10618]
loss: 1.21171	cur:[5000]\[10618]
loss: 1.17947	cur:[6000]\[10618]
loss: 1.18761	cur:[7000]\[10618]
loss: 1.19398	cur:[8000]\[10618]
loss: 1.19551	cur:[9000]\[10618]
loss: 1.21120	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.50543	cur:[250]\[1320]
loss: 1.49528	cur:[500]\[1320]
loss: 1.51829	cur:[750]\[1320]
loss: 1.50659	cur:[1000]\[1320]
loss: 1.45141	cur:[1250]\[1320]
epoch:38	bleu:0.03913
*************** epoch:39 ***************
loss: 1.17677	cur:[1000]\[10618]
loss: 1.19185	cur:[2000]\[10618]
loss: 1.20190	cur:[3000]\[10618]
loss: 1.18676	cur:[4000]\[10618]
loss: 1.18882	cur:[5000]\[10618]
loss: 1.18631	cur:[6000]\[10618]
loss: 1.18379	cur:[7000]\[10618]
loss: 1.19439	cur:[8000]\[10618]
loss: 1.17047	cur:[9000]\[10618]
loss: 1.18589	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.47877	cur:[250]\[1320]
loss: 1.48533	cur:[500]\[1320]
loss: 1.44771	cur:[750]\[1320]
loss: 1.43006	cur:[1000]\[1320]
loss: 1.49990	cur:[1250]\[1320]
epoch:39	bleu:0.02985
*************** epoch:40 ***************
loss: 1.19409	cur:[1000]\[10618]
loss: 1.18374	cur:[2000]\[10618]
loss: 1.17627	cur:[3000]\[10618]
loss: 1.18487	cur:[4000]\[10618]
loss: 1.18830	cur:[5000]\[10618]
loss: 1.17820	cur:[6000]\[10618]
loss: 1.17962	cur:[7000]\[10618]
loss: 1.18013	cur:[8000]\[10618]
loss: 1.17507	cur:[9000]\[10618]
loss: 1.17413	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.47027	cur:[250]\[1320]
loss: 1.52704	cur:[500]\[1320]
loss: 1.48554	cur:[750]\[1320]
loss: 1.46104	cur:[1000]\[1320]
loss: 1.45880	cur:[1250]\[1320]
save model at ./check_point5/epoch40.pth
epoch:40	bleu:0.00000
*************** epoch:41 ***************
loss: 1.18943	cur:[1000]\[10618]
loss: 1.17033	cur:[2000]\[10618]
loss: 1.15564	cur:[3000]\[10618]
loss: 1.16785	cur:[4000]\[10618]
loss: 1.16437	cur:[5000]\[10618]
loss: 1.15260	cur:[6000]\[10618]
loss: 1.14596	cur:[7000]\[10618]
loss: 1.18249	cur:[8000]\[10618]
loss: 1.14427	cur:[9000]\[10618]
loss: 1.16699	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.46870	cur:[250]\[1320]
loss: 1.41650	cur:[500]\[1320]
loss: 1.46785	cur:[750]\[1320]
loss: 1.49384	cur:[1000]\[1320]
loss: 1.55311	cur:[1250]\[1320]
epoch:41	bleu:0.00000
*************** epoch:42 ***************
loss: 1.17696	cur:[1000]\[10618]
loss: 1.15822	cur:[2000]\[10618]
loss: 1.16361	cur:[3000]\[10618]
loss: 1.16030	cur:[4000]\[10618]
loss: 1.16395	cur:[5000]\[10618]
loss: 1.16177	cur:[6000]\[10618]
loss: 1.18408	cur:[7000]\[10618]
loss: 1.15220	cur:[8000]\[10618]
loss: 1.15501	cur:[9000]\[10618]
loss: 1.15978	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.44905	cur:[250]\[1320]
loss: 1.44318	cur:[500]\[1320]
loss: 1.48184	cur:[750]\[1320]
loss: 1.47635	cur:[1000]\[1320]
loss: 1.49286	cur:[1250]\[1320]
epoch:42	bleu:0.04212
*************** epoch:43 ***************
loss: 1.14178	cur:[1000]\[10618]
loss: 1.16708	cur:[2000]\[10618]
loss: 1.16268	cur:[3000]\[10618]
loss: 1.15328	cur:[4000]\[10618]
loss: 1.13191	cur:[5000]\[10618]
loss: 1.16540	cur:[6000]\[10618]
loss: 1.14750	cur:[7000]\[10618]
loss: 1.14360	cur:[8000]\[10618]
loss: 1.14645	cur:[9000]\[10618]
loss: 1.14076	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.44332	cur:[250]\[1320]
loss: 1.41395	cur:[500]\[1320]
loss: 1.44176	cur:[750]\[1320]
loss: 1.44318	cur:[1000]\[1320]
loss: 1.48407	cur:[1250]\[1320]
epoch:43	bleu:0.00000
*************** epoch:44 ***************
loss: 1.14731	cur:[1000]\[10618]
loss: 1.13539	cur:[2000]\[10618]
loss: 1.15915	cur:[3000]\[10618]
loss: 1.13805	cur:[4000]\[10618]
loss: 1.15138	cur:[5000]\[10618]
loss: 1.14045	cur:[6000]\[10618]
loss: 1.12799	cur:[7000]\[10618]
loss: 1.13221	cur:[8000]\[10618]
loss: 1.14186	cur:[9000]\[10618]
loss: 1.15460	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.50295	cur:[250]\[1320]
loss: 1.47311	cur:[500]\[1320]
loss: 1.47766	cur:[750]\[1320]
loss: 1.42456	cur:[1000]\[1320]
loss: 1.42556	cur:[1250]\[1320]
epoch:44	bleu:0.05447
*************** epoch:45 ***************
loss: 1.12459	cur:[1000]\[10618]
loss: 1.15544	cur:[2000]\[10618]
loss: 1.14257	cur:[3000]\[10618]
loss: 1.13489	cur:[4000]\[10618]
loss: 1.12294	cur:[5000]\[10618]
loss: 1.11403	cur:[6000]\[10618]
loss: 1.12809	cur:[7000]\[10618]
loss: 1.13654	cur:[8000]\[10618]
loss: 1.12851	cur:[9000]\[10618]
loss: 1.13376	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.47086	cur:[250]\[1320]
loss: 1.47512	cur:[500]\[1320]
loss: 1.45943	cur:[750]\[1320]
loss: 1.47466	cur:[1000]\[1320]
loss: 1.46583	cur:[1250]\[1320]
save model at ./check_point5/best.pth
epoch:45	bleu:0.10000
*************** epoch:46 ***************
loss: 1.12075	cur:[1000]\[10618]
loss: 1.13019	cur:[2000]\[10618]
loss: 1.12608	cur:[3000]\[10618]
loss: 1.11350	cur:[4000]\[10618]
loss: 1.12794	cur:[5000]\[10618]
loss: 1.12565	cur:[6000]\[10618]
loss: 1.13358	cur:[7000]\[10618]
loss: 1.12921	cur:[8000]\[10618]
loss: 1.11384	cur:[9000]\[10618]
loss: 1.11250	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.44922	cur:[250]\[1320]
loss: 1.44172	cur:[500]\[1320]
loss: 1.55085	cur:[750]\[1320]
loss: 1.48290	cur:[1000]\[1320]
loss: 1.50947	cur:[1250]\[1320]
epoch:46	bleu:0.00880
*************** epoch:47 ***************
loss: 1.10401	cur:[1000]\[10618]
loss: 1.13143	cur:[2000]\[10618]
loss: 1.13261	cur:[3000]\[10618]
loss: 1.12032	cur:[4000]\[10618]
loss: 1.12396	cur:[5000]\[10618]
loss: 1.12081	cur:[6000]\[10618]
loss: 1.13082	cur:[7000]\[10618]
loss: 1.11249	cur:[8000]\[10618]
loss: 1.09509	cur:[9000]\[10618]
loss: 1.10670	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.41668	cur:[250]\[1320]
loss: 1.44974	cur:[500]\[1320]
loss: 1.46088	cur:[750]\[1320]
loss: 1.51780	cur:[1000]\[1320]
loss: 1.50734	cur:[1250]\[1320]
epoch:47	bleu:0.04038
*************** epoch:48 ***************
loss: 1.10494	cur:[1000]\[10618]
loss: 1.11802	cur:[2000]\[10618]
loss: 1.12794	cur:[3000]\[10618]
loss: 1.09924	cur:[4000]\[10618]
loss: 1.11966	cur:[5000]\[10618]
loss: 1.10731	cur:[6000]\[10618]
loss: 1.09778	cur:[7000]\[10618]
loss: 1.09437	cur:[8000]\[10618]
loss: 1.12223	cur:[9000]\[10618]
loss: 1.09769	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.47027	cur:[250]\[1320]
loss: 1.45541	cur:[500]\[1320]
loss: 1.48882	cur:[750]\[1320]
loss: 1.45104	cur:[1000]\[1320]
loss: 1.46493	cur:[1250]\[1320]
epoch:48	bleu:0.05679
*************** epoch:49 ***************
loss: 1.10765	cur:[1000]\[10618]
loss: 1.11876	cur:[2000]\[10618]
loss: 1.10345	cur:[3000]\[10618]
loss: 1.08046	cur:[4000]\[10618]
loss: 1.11748	cur:[5000]\[10618]
loss: 1.09863	cur:[6000]\[10618]
loss: 1.06479	cur:[7000]\[10618]
loss: 1.09591	cur:[8000]\[10618]
loss: 1.11639	cur:[9000]\[10618]
loss: 1.08605	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.47502	cur:[250]\[1320]
loss: 1.46522	cur:[500]\[1320]
loss: 1.49304	cur:[750]\[1320]
loss: 1.41624	cur:[1000]\[1320]
loss: 1.45666	cur:[1250]\[1320]
epoch:49	bleu:0.04079
*************** epoch:50 ***************
loss: 1.09358	cur:[1000]\[10618]
loss: 1.13116	cur:[2000]\[10618]
loss: 1.07669	cur:[3000]\[10618]
loss: 1.10162	cur:[4000]\[10618]
loss: 1.09651	cur:[5000]\[10618]
loss: 1.08362	cur:[6000]\[10618]
loss: 1.09591	cur:[7000]\[10618]
loss: 1.09382	cur:[8000]\[10618]
loss: 1.07449	cur:[9000]\[10618]
loss: 1.07939	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.49106	cur:[250]\[1320]
loss: 1.47202	cur:[500]\[1320]
loss: 1.41868	cur:[750]\[1320]
loss: 1.45975	cur:[1000]\[1320]
loss: 1.43498	cur:[1250]\[1320]
save model at ./check_point5/epoch50.pth
epoch:50	bleu:0.01652
*************** epoch:51 ***************
loss: 1.10149	cur:[1000]\[10618]
loss: 1.07974	cur:[2000]\[10618]
loss: 1.07659	cur:[3000]\[10618]
loss: 1.08488	cur:[4000]\[10618]
loss: 1.08141	cur:[5000]\[10618]
loss: 1.07847	cur:[6000]\[10618]
loss: 1.09161	cur:[7000]\[10618]
loss: 1.07967	cur:[8000]\[10618]
loss: 1.07818	cur:[9000]\[10618]
loss: 1.06579	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.51777	cur:[250]\[1320]
loss: 1.47272	cur:[500]\[1320]
loss: 1.41543	cur:[750]\[1320]
loss: 1.48068	cur:[1000]\[1320]
loss: 1.42603	cur:[1250]\[1320]
epoch:51	bleu:0.05728
*************** epoch:52 ***************
loss: 1.07534	cur:[1000]\[10618]
loss: 1.06983	cur:[2000]\[10618]
loss: 1.06917	cur:[3000]\[10618]
loss: 1.10557	cur:[4000]\[10618]
loss: 1.08240	cur:[5000]\[10618]
loss: 1.07324	cur:[6000]\[10618]
loss: 1.08011	cur:[7000]\[10618]
loss: 1.06018	cur:[8000]\[10618]
loss: 1.07737	cur:[9000]\[10618]
loss: 1.06003	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.44304	cur:[250]\[1320]
loss: 1.40000	cur:[500]\[1320]
loss: 1.52160	cur:[750]\[1320]
loss: 1.47336	cur:[1000]\[1320]
loss: 1.44191	cur:[1250]\[1320]
epoch:52	bleu:0.02705
Epoch    52: reducing learning rate of group 0 to 1.0000e-05.
Epoch    52: reducing learning rate of group 0 to 1.0000e-05.
*************** epoch:53 ***************
loss: 1.05771	cur:[1000]\[10618]
loss: 1.05464	cur:[2000]\[10618]
loss: 1.06830	cur:[3000]\[10618]
loss: 1.05957	cur:[4000]\[10618]
loss: 1.07011	cur:[5000]\[10618]
loss: 1.06346	cur:[6000]\[10618]
loss: 1.06899	cur:[7000]\[10618]
loss: 1.05356	cur:[8000]\[10618]
loss: 1.07715	cur:[9000]\[10618]
loss: 1.08144	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.44422	cur:[250]\[1320]
loss: 1.41835	cur:[500]\[1320]
loss: 1.49833	cur:[750]\[1320]
loss: 1.49293	cur:[1000]\[1320]
loss: 1.43950	cur:[1250]\[1320]
epoch:53	bleu:0.01963
*************** epoch:54 ***************
loss: 1.05972	cur:[1000]\[10618]
loss: 1.06007	cur:[2000]\[10618]
loss: 1.06823	cur:[3000]\[10618]
loss: 1.05847	cur:[4000]\[10618]
loss: 1.06467	cur:[5000]\[10618]
loss: 1.06546	cur:[6000]\[10618]
loss: 1.06311	cur:[7000]\[10618]
loss: 1.05921	cur:[8000]\[10618]
loss: 1.05485	cur:[9000]\[10618]
loss: 1.06692	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.45418	cur:[250]\[1320]
loss: 1.45763	cur:[500]\[1320]
loss: 1.45978	cur:[750]\[1320]
loss: 1.43195	cur:[1000]\[1320]
loss: 1.45755	cur:[1250]\[1320]
epoch:54	bleu:0.09715
*************** epoch:55 ***************
loss: 1.04033	cur:[1000]\[10618]
loss: 1.06871	cur:[2000]\[10618]
loss: 1.06045	cur:[3000]\[10618]
loss: 1.06495	cur:[4000]\[10618]
loss: 1.05212	cur:[5000]\[10618]
loss: 1.07868	cur:[6000]\[10618]
loss: 1.08326	cur:[7000]\[10618]
loss: 1.05296	cur:[8000]\[10618]
loss: 1.03669	cur:[9000]\[10618]
loss: 1.05068	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.42364	cur:[250]\[1320]
loss: 1.50593	cur:[500]\[1320]
loss: 1.44142	cur:[750]\[1320]
loss: 1.46602	cur:[1000]\[1320]
loss: 1.44313	cur:[1250]\[1320]
epoch:55	bleu:0.00000
*************** epoch:56 ***************
loss: 1.05155	cur:[1000]\[10618]
loss: 1.04626	cur:[2000]\[10618]
loss: 1.05686	cur:[3000]\[10618]
loss: 1.07425	cur:[4000]\[10618]
loss: 1.06484	cur:[5000]\[10618]
loss: 1.07103	cur:[6000]\[10618]
loss: 1.05305	cur:[7000]\[10618]
loss: 1.04737	cur:[8000]\[10618]
loss: 1.08212	cur:[9000]\[10618]
loss: 1.03866	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.49594	cur:[250]\[1320]
loss: 1.48910	cur:[500]\[1320]
loss: 1.47175	cur:[750]\[1320]
loss: 1.41737	cur:[1000]\[1320]
loss: 1.48788	cur:[1250]\[1320]
epoch:56	bleu:0.07600
*************** epoch:57 ***************
loss: 1.05906	cur:[1000]\[10618]
loss: 1.06093	cur:[2000]\[10618]
loss: 1.06126	cur:[3000]\[10618]
loss: 1.06988	cur:[4000]\[10618]
loss: 1.06335	cur:[5000]\[10618]
loss: 1.04978	cur:[6000]\[10618]
loss: 1.05304	cur:[7000]\[10618]
loss: 1.06220	cur:[8000]\[10618]
loss: 1.05863	cur:[9000]\[10618]
loss: 1.07250	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.45958	cur:[250]\[1320]
loss: 1.44496	cur:[500]\[1320]
loss: 1.50530	cur:[750]\[1320]
loss: 1.46967	cur:[1000]\[1320]
loss: 1.42273	cur:[1250]\[1320]
epoch:57	bleu:0.00000
*************** epoch:58 ***************
loss: 1.06730	cur:[1000]\[10618]
loss: 1.07311	cur:[2000]\[10618]
loss: 1.07088	cur:[3000]\[10618]
loss: 1.06742	cur:[4000]\[10618]
loss: 1.05637	cur:[5000]\[10618]
loss: 1.06261	cur:[6000]\[10618]
loss: 1.03519	cur:[7000]\[10618]
loss: 1.07722	cur:[8000]\[10618]
loss: 1.07413	cur:[9000]\[10618]
loss: 1.06449	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.43149	cur:[250]\[1320]
loss: 1.41081	cur:[500]\[1320]
loss: 1.43864	cur:[750]\[1320]
loss: 1.40255	cur:[1000]\[1320]
loss: 1.51187	cur:[1250]\[1320]
epoch:58	bleu:0.05000
*************** epoch:59 ***************
loss: 1.06046	cur:[1000]\[10618]
loss: 1.04966	cur:[2000]\[10618]
loss: 1.05634	cur:[3000]\[10618]
loss: 1.06907	cur:[4000]\[10618]
loss: 1.06009	cur:[5000]\[10618]
loss: 1.03740	cur:[6000]\[10618]
loss: 1.04714	cur:[7000]\[10618]
loss: 1.05266	cur:[8000]\[10618]
loss: 1.05509	cur:[9000]\[10618]
loss: 1.04344	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.44420	cur:[250]\[1320]
loss: 1.43825	cur:[500]\[1320]
loss: 1.44523	cur:[750]\[1320]
loss: 1.40235	cur:[1000]\[1320]
loss: 1.48170	cur:[1250]\[1320]
epoch:59	bleu:0.03938
*************** epoch:60 ***************
loss: 1.05776	cur:[1000]\[10618]
loss: 1.04850	cur:[2000]\[10618]
loss: 1.05987	cur:[3000]\[10618]
loss: 1.05004	cur:[4000]\[10618]
loss: 1.06472	cur:[5000]\[10618]
loss: 1.04001	cur:[6000]\[10618]
loss: 1.07294	cur:[7000]\[10618]
loss: 1.07206	cur:[8000]\[10618]
loss: 1.06684	cur:[9000]\[10618]
loss: 1.06081	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.43149	cur:[250]\[1320]
loss: 1.44596	cur:[500]\[1320]
loss: 1.50123	cur:[750]\[1320]
loss: 1.45825	cur:[1000]\[1320]
loss: 1.43101	cur:[1250]\[1320]
save model at ./check_point5/epoch60.pth
epoch:60	bleu:0.01446
*************** epoch:61 ***************
loss: 1.03348	cur:[1000]\[10618]
loss: 1.05355	cur:[2000]\[10618]
loss: 1.04942	cur:[3000]\[10618]
loss: 1.07110	cur:[4000]\[10618]
loss: 1.04804	cur:[5000]\[10618]
loss: 1.07421	cur:[6000]\[10618]
loss: 1.03883	cur:[7000]\[10618]
loss: 1.04430	cur:[8000]\[10618]
loss: 1.05539	cur:[9000]\[10618]
loss: 1.04466	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.45033	cur:[250]\[1320]
loss: 1.48031	cur:[500]\[1320]
loss: 1.42166	cur:[750]\[1320]
loss: 1.46527	cur:[1000]\[1320]
loss: 1.48758	cur:[1250]\[1320]
epoch:61	bleu:0.04079
*************** epoch:62 ***************
loss: 1.06343	cur:[1000]\[10618]
loss: 1.07142	cur:[2000]\[10618]
loss: 1.05413	cur:[3000]\[10618]
loss: 1.04584	cur:[4000]\[10618]
loss: 1.03943	cur:[5000]\[10618]
loss: 1.06593	cur:[6000]\[10618]
loss: 1.06207	cur:[7000]\[10618]
loss: 1.06572	cur:[8000]\[10618]
loss: 1.05363	cur:[9000]\[10618]
loss: 1.06481	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.43751	cur:[250]\[1320]
loss: 1.47683	cur:[500]\[1320]
loss: 1.43626	cur:[750]\[1320]
loss: 1.41705	cur:[1000]\[1320]
loss: 1.53357	cur:[1250]\[1320]
epoch:62	bleu:0.04229
*************** epoch:63 ***************
loss: 1.05357	cur:[1000]\[10618]
loss: 1.04357	cur:[2000]\[10618]
loss: 1.07325	cur:[3000]\[10618]
loss: 1.06048	cur:[4000]\[10618]
loss: 1.02242	cur:[5000]\[10618]
loss: 1.06079	cur:[6000]\[10618]
loss: 1.03794	cur:[7000]\[10618]
loss: 1.05071	cur:[8000]\[10618]
loss: 1.05127	cur:[9000]\[10618]
loss: 1.04434	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.48512	cur:[250]\[1320]
loss: 1.52682	cur:[500]\[1320]
loss: 1.44815	cur:[750]\[1320]
loss: 1.42708	cur:[1000]\[1320]
loss: 1.43673	cur:[1250]\[1320]
epoch:63	bleu:0.04023
*************** epoch:64 ***************
loss: 1.07444	cur:[1000]\[10618]
loss: 1.05575	cur:[2000]\[10618]
loss: 1.04771	cur:[3000]\[10618]
loss: 1.05446	cur:[4000]\[10618]
loss: 1.05291	cur:[5000]\[10618]
loss: 1.03489	cur:[6000]\[10618]
loss: 1.04589	cur:[7000]\[10618]
loss: 1.04757	cur:[8000]\[10618]
loss: 1.05057	cur:[9000]\[10618]
loss: 1.07605	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.45658	cur:[250]\[1320]
loss: 1.39855	cur:[500]\[1320]
loss: 1.45311	cur:[750]\[1320]
loss: 1.52561	cur:[1000]\[1320]
loss: 1.45415	cur:[1250]\[1320]
epoch:64	bleu:0.03913
*************** epoch:65 ***************
loss: 1.04285	cur:[1000]\[10618]
loss: 1.05217	cur:[2000]\[10618]
loss: 1.06975	cur:[3000]\[10618]
loss: 1.05524	cur:[4000]\[10618]
loss: 1.05621	cur:[5000]\[10618]
loss: 1.03722	cur:[6000]\[10618]
loss: 1.04661	cur:[7000]\[10618]
loss: 1.05947	cur:[8000]\[10618]
loss: 1.04108	cur:[9000]\[10618]
loss: 1.04774	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.43896	cur:[250]\[1320]
loss: 1.44868	cur:[500]\[1320]
loss: 1.47345	cur:[750]\[1320]
loss: 1.44924	cur:[1000]\[1320]
loss: 1.45214	cur:[1250]\[1320]
epoch:65	bleu:0.00000
*************** epoch:66 ***************
loss: 1.05059	cur:[1000]\[10618]
loss: 1.03596	cur:[2000]\[10618]
loss: 1.05192	cur:[3000]\[10618]
loss: 1.05408	cur:[4000]\[10618]
loss: 1.04695	cur:[5000]\[10618]
loss: 1.04861	cur:[6000]\[10618]
loss: 1.05604	cur:[7000]\[10618]
loss: 1.04058	cur:[8000]\[10618]
loss: 1.06776	cur:[9000]\[10618]
loss: 1.05822	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.49121	cur:[250]\[1320]
loss: 1.38609	cur:[500]\[1320]
loss: 1.48241	cur:[750]\[1320]
loss: 1.45818	cur:[1000]\[1320]
loss: 1.47456	cur:[1250]\[1320]
epoch:66	bleu:0.03738
*************** epoch:67 ***************
loss: 1.04766	cur:[1000]\[10618]
loss: 1.04893	cur:[2000]\[10618]
loss: 1.05689	cur:[3000]\[10618]
loss: 1.05456	cur:[4000]\[10618]
loss: 1.04485	cur:[5000]\[10618]
loss: 1.04777	cur:[6000]\[10618]
loss: 1.04888	cur:[7000]\[10618]
loss: 1.04395	cur:[8000]\[10618]
loss: 1.04051	cur:[9000]\[10618]
loss: 1.05245	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.44798	cur:[250]\[1320]
loss: 1.48591	cur:[500]\[1320]
loss: 1.47246	cur:[750]\[1320]
loss: 1.45213	cur:[1000]\[1320]
loss: 1.53390	cur:[1250]\[1320]
epoch:67	bleu:0.07056
Epoch    67: reducing learning rate of group 0 to 1.0000e-06.
Epoch    67: reducing learning rate of group 0 to 1.0000e-06.
*************** epoch:68 ***************
loss: 1.04136	cur:[1000]\[10618]
loss: 1.05121	cur:[2000]\[10618]
loss: 1.05766	cur:[3000]\[10618]
loss: 1.05159	cur:[4000]\[10618]
loss: 1.04707	cur:[5000]\[10618]
loss: 1.02471	cur:[6000]\[10618]
loss: 1.04775	cur:[7000]\[10618]
loss: 1.03495	cur:[8000]\[10618]
loss: 1.05408	cur:[9000]\[10618]
loss: 1.04496	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.40640	cur:[250]\[1320]
loss: 1.50119	cur:[500]\[1320]
loss: 1.48094	cur:[750]\[1320]
loss: 1.46008	cur:[1000]\[1320]
loss: 1.43735	cur:[1250]\[1320]
epoch:68	bleu:0.02738
*************** epoch:69 ***************
loss: 1.06674	cur:[1000]\[10618]
loss: 1.03090	cur:[2000]\[10618]
loss: 1.04534	cur:[3000]\[10618]
loss: 1.04748	cur:[4000]\[10618]
loss: 1.05585	cur:[5000]\[10618]
loss: 1.04468	cur:[6000]\[10618]
loss: 1.05439	cur:[7000]\[10618]
loss: 1.07508	cur:[8000]\[10618]
loss: 1.05717	cur:[9000]\[10618]
loss: 1.02877	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.43750	cur:[250]\[1320]
loss: 1.49081	cur:[500]\[1320]
loss: 1.47671	cur:[750]\[1320]
loss: 1.48439	cur:[1000]\[1320]
loss: 1.39700	cur:[1250]\[1320]
epoch:69	bleu:0.02399
*************** epoch:70 ***************
loss: 1.05736	cur:[1000]\[10618]
loss: 1.06027	cur:[2000]\[10618]
loss: 1.04752	cur:[3000]\[10618]
loss: 1.04641	cur:[4000]\[10618]
loss: 1.05610	cur:[5000]\[10618]
loss: 1.04482	cur:[6000]\[10618]
loss: 1.02842	cur:[7000]\[10618]
loss: 1.05107	cur:[8000]\[10618]
loss: 1.04993	cur:[9000]\[10618]
loss: 1.04900	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.46800	cur:[250]\[1320]
loss: 1.43030	cur:[500]\[1320]
loss: 1.49593	cur:[750]\[1320]
loss: 1.50495	cur:[1000]\[1320]
loss: 1.46019	cur:[1250]\[1320]
save model at ./check_point5/epoch70.pth
epoch:70	bleu:0.00000
*************** epoch:71 ***************
loss: 1.05430	cur:[1000]\[10618]
loss: 1.02994	cur:[2000]\[10618]
loss: 1.05511	cur:[3000]\[10618]
loss: 1.03846	cur:[4000]\[10618]
loss: 1.05219	cur:[5000]\[10618]
loss: 1.04495	cur:[6000]\[10618]
loss: 1.07570	cur:[7000]\[10618]
loss: 1.06510	cur:[8000]\[10618]
loss: 1.05001	cur:[9000]\[10618]
loss: 1.03194	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.40543	cur:[250]\[1320]
loss: 1.47772	cur:[500]\[1320]
loss: 1.48538	cur:[750]\[1320]
loss: 1.45156	cur:[1000]\[1320]
loss: 1.49225	cur:[1250]\[1320]
epoch:71	bleu:0.04204
*************** epoch:72 ***************
loss: 1.05377	cur:[1000]\[10618]
loss: 1.03437	cur:[2000]\[10618]
loss: 1.05288	cur:[3000]\[10618]
loss: 1.03648	cur:[4000]\[10618]
loss: 1.04636	cur:[5000]\[10618]
loss: 1.07137	cur:[6000]\[10618]
loss: 1.05174	cur:[7000]\[10618]
loss: 1.02855	cur:[8000]\[10618]
loss: 1.05358	cur:[9000]\[10618]
loss: 1.06179	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.46247	cur:[250]\[1320]
loss: 1.46299	cur:[500]\[1320]
loss: 1.45498	cur:[750]\[1320]
loss: 1.50868	cur:[1000]\[1320]
loss: 1.40866	cur:[1250]\[1320]
epoch:72	bleu:0.08474
*************** epoch:73 ***************
loss: 1.05840	cur:[1000]\[10618]
loss: 1.03652	cur:[2000]\[10618]
loss: 1.06010	cur:[3000]\[10618]
loss: 1.03911	cur:[4000]\[10618]
loss: 1.04970	cur:[5000]\[10618]
loss: 1.04933	cur:[6000]\[10618]
loss: 1.05679	cur:[7000]\[10618]
loss: 1.03376	cur:[8000]\[10618]
loss: 1.05281	cur:[9000]\[10618]
loss: 1.04269	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.46330	cur:[250]\[1320]
loss: 1.44618	cur:[500]\[1320]
loss: 1.46448	cur:[750]\[1320]
loss: 1.41410	cur:[1000]\[1320]
loss: 1.46450	cur:[1250]\[1320]
epoch:73	bleu:0.09526
*************** epoch:74 ***************
loss: 1.04770	cur:[1000]\[10618]
loss: 1.04123	cur:[2000]\[10618]
loss: 1.05044	cur:[3000]\[10618]
loss: 1.04888	cur:[4000]\[10618]
loss: 1.03805	cur:[5000]\[10618]
loss: 1.03409	cur:[6000]\[10618]
loss: 1.04267	cur:[7000]\[10618]
loss: 1.05328	cur:[8000]\[10618]
loss: 1.04605	cur:[9000]\[10618]
loss: 1.03875	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.46122	cur:[250]\[1320]
loss: 1.43624	cur:[500]\[1320]
loss: 1.48576	cur:[750]\[1320]
loss: 1.49247	cur:[1000]\[1320]
loss: 1.46058	cur:[1250]\[1320]
epoch:74	bleu:0.02158
*************** epoch:75 ***************
loss: 1.05016	cur:[1000]\[10618]
loss: 1.03427	cur:[2000]\[10618]
loss: 1.05454	cur:[3000]\[10618]
loss: 1.04818	cur:[4000]\[10618]
loss: 1.04761	cur:[5000]\[10618]
loss: 1.05966	cur:[6000]\[10618]
loss: 1.05384	cur:[7000]\[10618]
loss: 1.06240	cur:[8000]\[10618]
loss: 1.03846	cur:[9000]\[10618]
loss: 1.01355	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.42600	cur:[250]\[1320]
loss: 1.40470	cur:[500]\[1320]
loss: 1.47631	cur:[750]\[1320]
loss: 1.47372	cur:[1000]\[1320]
loss: 1.47001	cur:[1250]\[1320]
epoch:75	bleu:0.01844
*************** epoch:76 ***************
loss: 1.06336	cur:[1000]\[10618]
loss: 1.04860	cur:[2000]\[10618]
loss: 1.05794	cur:[3000]\[10618]
loss: 1.06332	cur:[4000]\[10618]
loss: 1.04099	cur:[5000]\[10618]
loss: 1.04129	cur:[6000]\[10618]
loss: 1.05488	cur:[7000]\[10618]
loss: 1.03612	cur:[8000]\[10618]
loss: 1.04580	cur:[9000]\[10618]
loss: 1.04787	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.42724	cur:[250]\[1320]
loss: 1.46490	cur:[500]\[1320]
loss: 1.45558	cur:[750]\[1320]
loss: 1.47155	cur:[1000]\[1320]
loss: 1.46090	cur:[1250]\[1320]
epoch:76	bleu:0.02778
*************** epoch:77 ***************
loss: 1.02368	cur:[1000]\[10618]
loss: 1.03601	cur:[2000]\[10618]
loss: 1.05539	cur:[3000]\[10618]
loss: 1.05283	cur:[4000]\[10618]
loss: 1.06175	cur:[5000]\[10618]
loss: 1.04563	cur:[6000]\[10618]
loss: 1.05048	cur:[7000]\[10618]
loss: 1.06372	cur:[8000]\[10618]
loss: 1.05420	cur:[9000]\[10618]
loss: 1.05438	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.45092	cur:[250]\[1320]
loss: 1.50445	cur:[500]\[1320]
loss: 1.49297	cur:[750]\[1320]
loss: 1.48301	cur:[1000]\[1320]
loss: 1.45434	cur:[1250]\[1320]
save model at ./check_point5/best.pth
epoch:77	bleu:0.12261
*************** epoch:78 ***************
loss: 1.02423	cur:[1000]\[10618]
loss: 1.04592	cur:[2000]\[10618]
loss: 1.05639	cur:[3000]\[10618]
loss: 1.05503	cur:[4000]\[10618]
loss: 1.03125	cur:[5000]\[10618]
loss: 1.05116	cur:[6000]\[10618]
loss: 1.05487	cur:[7000]\[10618]
loss: 1.05791	cur:[8000]\[10618]
loss: 1.05502	cur:[9000]\[10618]
loss: 1.05225	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.45232	cur:[250]\[1320]
loss: 1.40681	cur:[500]\[1320]
loss: 1.46788	cur:[750]\[1320]
loss: 1.48237	cur:[1000]\[1320]
loss: 1.42815	cur:[1250]\[1320]
epoch:78	bleu:0.07705
*************** epoch:79 ***************
loss: 1.07113	cur:[1000]\[10618]
loss: 1.05549	cur:[2000]\[10618]
loss: 1.02948	cur:[3000]\[10618]
loss: 1.04858	cur:[4000]\[10618]
loss: 1.04414	cur:[5000]\[10618]
loss: 1.04433	cur:[6000]\[10618]
loss: 1.03798	cur:[7000]\[10618]
loss: 1.05553	cur:[8000]\[10618]
loss: 1.05323	cur:[9000]\[10618]
loss: 1.02981	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.46884	cur:[250]\[1320]
loss: 1.39233	cur:[500]\[1320]
loss: 1.48186	cur:[750]\[1320]
loss: 1.46094	cur:[1000]\[1320]
loss: 1.47422	cur:[1250]\[1320]
epoch:79	bleu:0.02471
*************** epoch:80 ***************
loss: 1.05587	cur:[1000]\[10618]
loss: 1.04315	cur:[2000]\[10618]
loss: 1.06016	cur:[3000]\[10618]
loss: 1.04354	cur:[4000]\[10618]
loss: 1.02981	cur:[5000]\[10618]
loss: 1.04211	cur:[6000]\[10618]
loss: 1.06173	cur:[7000]\[10618]
loss: 1.06568	cur:[8000]\[10618]
loss: 1.05829	cur:[9000]\[10618]
loss: 1.03916	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.48793	cur:[250]\[1320]
loss: 1.46919	cur:[500]\[1320]
loss: 1.46419	cur:[750]\[1320]
loss: 1.50705	cur:[1000]\[1320]
loss: 1.43452	cur:[1250]\[1320]
save model at ./check_point5/epoch80.pth
epoch:80	bleu:0.01729
*************** epoch:81 ***************
loss: 1.04002	cur:[1000]\[10618]
loss: 1.05433	cur:[2000]\[10618]
loss: 1.04756	cur:[3000]\[10618]
loss: 1.04211	cur:[4000]\[10618]
loss: 1.03752	cur:[5000]\[10618]
loss: 1.05041	cur:[6000]\[10618]
loss: 1.02620	cur:[7000]\[10618]
loss: 1.03434	cur:[8000]\[10618]
loss: 1.05219	cur:[9000]\[10618]
loss: 1.05585	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.45461	cur:[250]\[1320]
loss: 1.44205	cur:[500]\[1320]
loss: 1.47771	cur:[750]\[1320]
loss: 1.48415	cur:[1000]\[1320]
loss: 1.43877	cur:[1250]\[1320]
epoch:81	bleu:0.02174
Epoch    81: reducing learning rate of group 0 to 1.0000e-07.
Epoch    81: reducing learning rate of group 0 to 1.0000e-07.
*************** epoch:82 ***************
loss: 1.04035	cur:[1000]\[10618]
loss: 1.07252	cur:[2000]\[10618]
loss: 1.05183	cur:[3000]\[10618]
loss: 1.04676	cur:[4000]\[10618]
loss: 1.04154	cur:[5000]\[10618]
loss: 1.04968	cur:[6000]\[10618]
loss: 1.05836	cur:[7000]\[10618]
loss: 1.05884	cur:[8000]\[10618]
loss: 1.06007	cur:[9000]\[10618]
loss: 1.05095	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.47197	cur:[250]\[1320]
loss: 1.44060	cur:[500]\[1320]
loss: 1.45830	cur:[750]\[1320]
loss: 1.45165	cur:[1000]\[1320]
loss: 1.46906	cur:[1250]\[1320]
epoch:82	bleu:0.00000
*************** epoch:83 ***************
loss: 1.06020	cur:[1000]\[10618]
loss: 1.06106	cur:[2000]\[10618]
loss: 1.05374	cur:[3000]\[10618]
loss: 1.05676	cur:[4000]\[10618]
loss: 1.05017	cur:[5000]\[10618]
loss: 1.04507	cur:[6000]\[10618]
loss: 1.06184	cur:[7000]\[10618]
loss: 1.05271	cur:[8000]\[10618]
loss: 1.04383	cur:[9000]\[10618]
loss: 1.04001	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.44029	cur:[250]\[1320]
loss: 1.47886	cur:[500]\[1320]
loss: 1.38513	cur:[750]\[1320]
loss: 1.45584	cur:[1000]\[1320]
loss: 1.50407	cur:[1250]\[1320]
epoch:83	bleu:0.00000
*************** epoch:84 ***************
loss: 1.05212	cur:[1000]\[10618]
loss: 1.03652	cur:[2000]\[10618]
loss: 1.03373	cur:[3000]\[10618]
loss: 1.03793	cur:[4000]\[10618]
loss: 1.04739	cur:[5000]\[10618]
loss: 1.03899	cur:[6000]\[10618]
loss: 1.05383	cur:[7000]\[10618]
loss: 1.04684	cur:[8000]\[10618]
loss: 1.06341	cur:[9000]\[10618]
loss: 1.04292	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.49783	cur:[250]\[1320]
loss: 1.48719	cur:[500]\[1320]
loss: 1.52097	cur:[750]\[1320]
loss: 1.44812	cur:[1000]\[1320]
loss: 1.45757	cur:[1250]\[1320]
epoch:84	bleu:0.01298
*************** epoch:85 ***************
loss: 1.04573	cur:[1000]\[10618]
loss: 1.05539	cur:[2000]\[10618]
loss: 1.04298	cur:[3000]\[10618]
loss: 1.05833	cur:[4000]\[10618]
loss: 1.06346	cur:[5000]\[10618]
loss: 1.03949	cur:[6000]\[10618]
loss: 1.04661	cur:[7000]\[10618]
loss: 1.04513	cur:[8000]\[10618]
loss: 1.05644	cur:[9000]\[10618]
loss: 1.04288	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.45637	cur:[250]\[1320]
loss: 1.43492	cur:[500]\[1320]
loss: 1.43590	cur:[750]\[1320]
loss: 1.50483	cur:[1000]\[1320]
loss: 1.49686	cur:[1250]\[1320]
epoch:85	bleu:0.04271
*************** epoch:86 ***************
loss: 1.05560	cur:[1000]\[10618]
loss: 1.04341	cur:[2000]\[10618]
loss: 1.03547	cur:[3000]\[10618]
loss: 1.05188	cur:[4000]\[10618]
loss: 1.04077	cur:[5000]\[10618]
loss: 1.05229	cur:[6000]\[10618]
loss: 1.04383	cur:[7000]\[10618]
loss: 1.05407	cur:[8000]\[10618]
loss: 1.03386	cur:[9000]\[10618]
loss: 1.03805	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.46248	cur:[250]\[1320]
loss: 1.45206	cur:[500]\[1320]
loss: 1.44138	cur:[750]\[1320]
loss: 1.47332	cur:[1000]\[1320]
loss: 1.46145	cur:[1250]\[1320]
epoch:86	bleu:0.01511
*************** epoch:87 ***************
loss: 1.04732	cur:[1000]\[10618]
loss: 1.05253	cur:[2000]\[10618]
loss: 1.03988	cur:[3000]\[10618]
loss: 1.04346	cur:[4000]\[10618]
loss: 1.04002	cur:[5000]\[10618]
loss: 1.04094	cur:[6000]\[10618]
loss: 1.04772	cur:[7000]\[10618]
loss: 1.04940	cur:[8000]\[10618]
loss: 1.05553	cur:[9000]\[10618]
loss: 1.05944	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.43609	cur:[250]\[1320]
loss: 1.43852	cur:[500]\[1320]
loss: 1.43723	cur:[750]\[1320]
loss: 1.42736	cur:[1000]\[1320]
loss: 1.49915	cur:[1250]\[1320]
epoch:87	bleu:0.08182
*************** epoch:88 ***************
loss: 1.04685	cur:[1000]\[10618]
loss: 1.04416	cur:[2000]\[10618]
loss: 1.05302	cur:[3000]\[10618]
loss: 1.04106	cur:[4000]\[10618]
loss: 1.03659	cur:[5000]\[10618]
loss: 1.05625	cur:[6000]\[10618]
loss: 1.03782	cur:[7000]\[10618]
loss: 1.04080	cur:[8000]\[10618]
loss: 1.03259	cur:[9000]\[10618]
loss: 1.03627	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.49450	cur:[250]\[1320]
loss: 1.44860	cur:[500]\[1320]
loss: 1.40964	cur:[750]\[1320]
loss: 1.55333	cur:[1000]\[1320]
loss: 1.44351	cur:[1250]\[1320]
epoch:88	bleu:0.07056
*************** epoch:89 ***************
loss: 1.04995	cur:[1000]\[10618]
loss: 1.04201	cur:[2000]\[10618]
loss: 1.05356	cur:[3000]\[10618]
loss: 1.04107	cur:[4000]\[10618]
loss: 1.04108	cur:[5000]\[10618]
loss: 1.01167	cur:[6000]\[10618]
loss: 1.02715	cur:[7000]\[10618]
loss: 1.05106	cur:[8000]\[10618]
loss: 1.05770	cur:[9000]\[10618]
loss: 1.03645	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.44258	cur:[250]\[1320]
loss: 1.43641	cur:[500]\[1320]
loss: 1.43231	cur:[750]\[1320]
loss: 1.55658	cur:[1000]\[1320]
loss: 1.48053	cur:[1250]\[1320]
epoch:89	bleu:0.02585
*************** epoch:90 ***************
loss: 1.04950	cur:[1000]\[10618]
loss: 1.05525	cur:[2000]\[10618]
loss: 1.04685	cur:[3000]\[10618]
loss: 1.05300	cur:[4000]\[10618]
loss: 1.04012	cur:[5000]\[10618]
loss: 1.04331	cur:[6000]\[10618]
loss: 1.06648	cur:[7000]\[10618]
loss: 1.03987	cur:[8000]\[10618]
loss: 1.05144	cur:[9000]\[10618]
loss: 1.04541	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.43754	cur:[250]\[1320]
loss: 1.40551	cur:[500]\[1320]
loss: 1.40912	cur:[750]\[1320]
loss: 1.51893	cur:[1000]\[1320]
loss: 1.44988	cur:[1250]\[1320]
save model at ./check_point5/epoch90.pth
epoch:90	bleu:0.00779
*************** epoch:91 ***************
loss: 1.05616	cur:[1000]\[10618]
loss: 1.04891	cur:[2000]\[10618]
loss: 1.04167	cur:[3000]\[10618]
loss: 1.02854	cur:[4000]\[10618]
loss: 1.05610	cur:[5000]\[10618]
loss: 1.04056	cur:[6000]\[10618]
loss: 1.04699	cur:[7000]\[10618]
loss: 1.04882	cur:[8000]\[10618]
loss: 1.04854	cur:[9000]\[10618]
loss: 1.04205	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.43990	cur:[250]\[1320]
loss: 1.45458	cur:[500]\[1320]
loss: 1.50847	cur:[750]\[1320]
loss: 1.44062	cur:[1000]\[1320]
loss: 1.49982	cur:[1250]\[1320]
epoch:91	bleu:0.06908
*************** epoch:92 ***************
loss: 1.04945	cur:[1000]\[10618]
loss: 1.05190	cur:[2000]\[10618]
loss: 1.06032	cur:[3000]\[10618]
loss: 1.03362	cur:[4000]\[10618]
loss: 1.04614	cur:[5000]\[10618]
loss: 1.05584	cur:[6000]\[10618]
loss: 1.04120	cur:[7000]\[10618]
loss: 1.03677	cur:[8000]\[10618]
loss: 1.03717	cur:[9000]\[10618]
loss: 1.04685	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.44859	cur:[250]\[1320]
loss: 1.50465	cur:[500]\[1320]
loss: 1.45762	cur:[750]\[1320]
loss: 1.51843	cur:[1000]\[1320]
loss: 1.52877	cur:[1250]\[1320]
epoch:92	bleu:0.07482
*************** epoch:93 ***************
loss: 1.05109	cur:[1000]\[10618]
loss: 1.02760	cur:[2000]\[10618]
loss: 1.04596	cur:[3000]\[10618]
loss: 1.03266	cur:[4000]\[10618]
loss: 1.05296	cur:[5000]\[10618]
loss: 1.03412	cur:[6000]\[10618]
loss: 1.05001	cur:[7000]\[10618]
loss: 1.03361	cur:[8000]\[10618]
loss: 1.05061	cur:[9000]\[10618]
loss: 1.03054	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.45121	cur:[250]\[1320]
loss: 1.46744	cur:[500]\[1320]
loss: 1.44491	cur:[750]\[1320]
loss: 1.49899	cur:[1000]\[1320]
loss: 1.41710	cur:[1250]\[1320]
epoch:93	bleu:0.03788
*************** epoch:94 ***************
loss: 1.05492	cur:[1000]\[10618]
loss: 1.04322	cur:[2000]\[10618]
loss: 1.03612	cur:[3000]\[10618]
loss: 1.05313	cur:[4000]\[10618]
loss: 1.04367	cur:[5000]\[10618]
loss: 1.04930	cur:[6000]\[10618]
loss: 1.05189	cur:[7000]\[10618]
loss: 1.03307	cur:[8000]\[10618]
loss: 1.05128	cur:[9000]\[10618]
loss: 1.03798	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.44462	cur:[250]\[1320]
loss: 1.45474	cur:[500]\[1320]
loss: 1.44986	cur:[750]\[1320]
loss: 1.51010	cur:[1000]\[1320]
loss: 1.48504	cur:[1250]\[1320]
epoch:94	bleu:0.02973
*************** epoch:95 ***************
loss: 1.03816	cur:[1000]\[10618]
loss: 1.05418	cur:[2000]\[10618]
loss: 1.05316	cur:[3000]\[10618]
loss: 1.04292	cur:[4000]\[10618]
loss: 1.03834	cur:[5000]\[10618]
loss: 1.04987	cur:[6000]\[10618]
loss: 1.04134	cur:[7000]\[10618]
loss: 1.03767	cur:[8000]\[10618]
loss: 1.06875	cur:[9000]\[10618]
loss: 1.05601	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.44403	cur:[250]\[1320]
loss: 1.49167	cur:[500]\[1320]
loss: 1.47575	cur:[750]\[1320]
loss: 1.46266	cur:[1000]\[1320]
loss: 1.48838	cur:[1250]\[1320]
epoch:95	bleu:0.08353
*************** epoch:96 ***************
loss: 1.03621	cur:[1000]\[10618]
loss: 1.05007	cur:[2000]\[10618]
loss: 1.05378	cur:[3000]\[10618]
loss: 1.04264	cur:[4000]\[10618]
loss: 1.03978	cur:[5000]\[10618]
loss: 1.05310	cur:[6000]\[10618]
loss: 1.04606	cur:[7000]\[10618]
loss: 1.03902	cur:[8000]\[10618]
loss: 1.03005	cur:[9000]\[10618]
loss: 1.06066	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.47694	cur:[250]\[1320]
loss: 1.45842	cur:[500]\[1320]
loss: 1.49035	cur:[750]\[1320]
loss: 1.41311	cur:[1000]\[1320]
loss: 1.48730	cur:[1250]\[1320]
epoch:96	bleu:0.05491
*************** epoch:97 ***************
loss: 1.02808	cur:[1000]\[10618]
loss: 1.03798	cur:[2000]\[10618]
loss: 1.03902	cur:[3000]\[10618]
loss: 1.06063	cur:[4000]\[10618]
loss: 1.03348	cur:[5000]\[10618]
loss: 1.03997	cur:[6000]\[10618]
loss: 1.04137	cur:[7000]\[10618]
loss: 1.05075	cur:[8000]\[10618]
loss: 1.05279	cur:[9000]\[10618]
loss: 1.06068	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.45780	cur:[250]\[1320]
loss: 1.46594	cur:[500]\[1320]
loss: 1.45514	cur:[750]\[1320]
loss: 1.45997	cur:[1000]\[1320]
loss: 1.42598	cur:[1250]\[1320]
epoch:97	bleu:0.01775
*************** epoch:98 ***************
loss: 1.03828	cur:[1000]\[10618]
loss: 1.05819	cur:[2000]\[10618]
loss: 1.03958	cur:[3000]\[10618]
loss: 1.04231	cur:[4000]\[10618]
loss: 1.06959	cur:[5000]\[10618]
loss: 1.04898	cur:[6000]\[10618]
loss: 1.02122	cur:[7000]\[10618]
loss: 1.05521	cur:[8000]\[10618]
loss: 1.02429	cur:[9000]\[10618]
loss: 1.02934	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.44720	cur:[250]\[1320]
loss: 1.43577	cur:[500]\[1320]
loss: 1.46269	cur:[750]\[1320]
loss: 1.49465	cur:[1000]\[1320]
loss: 1.46878	cur:[1250]\[1320]
epoch:98	bleu:0.00000
*************** epoch:99 ***************
loss: 1.06597	cur:[1000]\[10618]
loss: 1.04619	cur:[2000]\[10618]
loss: 1.03532	cur:[3000]\[10618]
loss: 1.06297	cur:[4000]\[10618]
loss: 1.02690	cur:[5000]\[10618]
loss: 1.04871	cur:[6000]\[10618]
loss: 1.03961	cur:[7000]\[10618]
loss: 1.04748	cur:[8000]\[10618]
loss: 1.02818	cur:[9000]\[10618]
loss: 1.05232	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.47478	cur:[250]\[1320]
loss: 1.47027	cur:[500]\[1320]
loss: 1.45603	cur:[750]\[1320]
loss: 1.45567	cur:[1000]\[1320]
loss: 1.47581	cur:[1250]\[1320]
epoch:99	bleu:0.04429
*************** epoch:100 ***************
loss: 1.04583	cur:[1000]\[10618]
loss: 1.05475	cur:[2000]\[10618]
loss: 1.04731	cur:[3000]\[10618]
loss: 1.03731	cur:[4000]\[10618]
loss: 1.03392	cur:[5000]\[10618]
loss: 1.04350	cur:[6000]\[10618]
loss: 1.05432	cur:[7000]\[10618]
loss: 1.04732	cur:[8000]\[10618]
loss: 1.04893	cur:[9000]\[10618]
loss: 1.04351	cur:[10000]\[10618]
--------------- Evaluation ---------------
loss: 1.45147	cur:[250]\[1320]
loss: 1.45934	cur:[500]\[1320]
loss: 1.44750	cur:[750]\[1320]
loss: 1.48976	cur:[1000]\[1320]
loss: 1.45991	cur:[1250]\[1320]
save model at ./check_point5/epoch100.pth
epoch:100	bleu:0.03518
